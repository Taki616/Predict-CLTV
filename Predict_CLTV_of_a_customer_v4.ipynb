{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm\n",
        "\n",
        "#!pip install pandas-profiling\n",
        "!pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip \n",
        "!pip install pyyaml==5.4.1"
      ],
      "metadata": {
        "id": "2ToP9M30Tpty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H4KXzR-QnCHP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from lightgbm import LGBMRegressor\n",
        "import warnings\n",
        "from pandas_profiling import ProfileReport\n",
        "from google.colab import files\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.read_csv(\"/content/train_BRCpofr.csv\")\n",
        "test=pd.read_csv(\"/content/test_koRSKBP.csv\")\n"
      ],
      "metadata": {
        "id": "U4NHwJ3Ln7eF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profile = ProfileReport(train, title='EDA', html={'style':{'full_width':True}})\n",
        "profile.to_file(\"EDA.html\")\n",
        "files.download(\"EDA.html\")"
      ],
      "metadata": {
        "id": "o2l-9te3mrYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Preprocessing updated\n",
        "y=train[\"cltv\"]\n",
        "\n",
        "#taking 5th-95th percentile of cltv based on area\n",
        "cltv_5 = train.groupby(['area'])[\"cltv\"].apply(lambda arr: np.percentile(arr,5)).rename('cltv_5')\n",
        "cltv_95 = train.groupby(['area'])[\"cltv\"].apply(lambda arr: np.percentile(arr,95)).rename('cltv_95')\n",
        "train = train.merge(cltv_95, on=['area'], how='left')\n",
        "train = train.merge(cltv_5, on=['area'], how='left')\n",
        "\n",
        "#taking 5th-95th percentile of cltv based on num_policies\n",
        "cltv_num_policies_5 = train.groupby(['num_policies'])[\"cltv\"].apply(lambda arr: np.percentile(arr,5)).rename('cltv_num_policies_5')\n",
        "cltv_num_policies_95 = train.groupby(['num_policies'])[\"cltv\"].apply(lambda arr: np.percentile(arr,95)).rename('cltv_num_policies_95')\n",
        "train = train.merge(cltv_num_policies_95, on=['num_policies'], how='left')\n",
        "train = train.merge(cltv_num_policies_5, on=['num_policies'], how='left')\n",
        "\n",
        "X=train.drop([\"cltv\",\"id\"],axis=1)\n",
        "\n",
        "# Standardizing numerical feature\n",
        "scaler=StandardScaler()\n",
        "scaler.fit(X[['claim_amount']])\n",
        "X['claim_amount'] = scaler.transform(X[['claim_amount']])\n",
        "\n",
        "\n",
        "scaler=StandardScaler()\n",
        "scaler.fit(X[['vintage']])\n",
        "X['vintage'] = scaler.transform(X[['vintage']])\n",
        "\n",
        "scaler=StandardScaler()\n",
        "scaler.fit(X[['cltv_5']])\n",
        "X['cltv_5'] = scaler.transform(X[['cltv_5']])\n",
        "\n",
        "scaler=StandardScaler()\n",
        "scaler.fit(X[['cltv_95']])\n",
        "X['cltv_95'] = scaler.transform(X[['cltv_95']])\n",
        "\n",
        "scaler=StandardScaler()\n",
        "scaler.fit(X[['cltv_num_policies_95']])\n",
        "X['cltv_num_policies_95'] = scaler.transform(X[['cltv_num_policies_95']])\n",
        "\n",
        "scaler=StandardScaler()\n",
        "scaler.fit(X[['cltv_num_policies_5']])\n",
        "X['cltv_num_policies_5'] = scaler.transform(X[['cltv_num_policies_5']])\n",
        "\n",
        "\n",
        "# One-hot encode the categorical feature\n",
        "X = pd.get_dummies(X, columns=[\"gender\",\"area\",\"qualification\",\"income\",\"num_policies\",\"policy\",\"type_of_policy\"])\n",
        "\n",
        "#Split your data.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
      ],
      "metadata": {
        "id": "OFhNm8FGhNBY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train Model\n",
        "\n",
        "# Train the LightGBM model\n",
        "model = LGBMRegressor(random_state=42)\n",
        "#model.fit(X_train, y_train)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'num_leaves': [31, 63, 127],\n",
        "    'learning_rate': [0.1, 0.05, 0.01],\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [-1, 5, 10],\n",
        "    'min_data_in_leaf': [10, 20, 30]\n",
        "}\n",
        "\n",
        "# Create the grid search object\n",
        "grid_search = GridSearchCV(model, param_grid, cv=3, n_jobs=-1)\n",
        "\n",
        "# Fit the grid search object to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# best set of hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Train a new model using the best set of hyperparameters\n",
        "best_model = LGBMRegressor(**best_params)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekSEMZz_s8KA",
        "outputId": "1cbef45b-2bb1-4cc9-c199-04fd18b38ee3",
        "cellView": "form"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, estimator=LGBMRegressor(random_state=42), n_jobs=-1,\n",
              "             param_grid={'learning_rate': [0.1, 0.05, 0.01],\n",
              "                         'max_depth': [-1, 5, 10],\n",
              "                         'min_data_in_leaf': [10, 20, 30],\n",
              "                         'n_estimators': [100, 200, 300],\n",
              "                         'num_leaves': [31, 63, 127]})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title R2 score on seen and unseen data\n",
        "\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "r2_score_train= r2_score(y_train,y_train_pred)\n",
        "print(\"r2_score on train data \", r2_score_train)\n",
        "\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "r2_score_test= r2_score(y_test,y_test_pred)\n",
        "print(\"r2_score on unseen data \", r2_score_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBAnhaFYD62S",
        "outputId": "c32dc194-8e6a-4004-cc71-d51fd4262c01",
        "cellView": "form"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r2_score on train data  0.1690478689285697\n",
            "r2_score on unseen data  0.1640679146580054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Predicting CLTV for the given Test File\n",
        "\n",
        "#dataframe for storing test result\n",
        "Predict_CLTV =pd.DataFrame()\n",
        "Predict_CLTV['id']=test[\"id\"]\n",
        "test=test.drop([\"id\"],axis=1)\n",
        "\n",
        "test = test.merge(cltv_95, on=['area'], how='left')\n",
        "test = test.merge(cltv_5, on=['area'], how='left')\n",
        "\n",
        "test = test.merge(cltv_num_policies_95, on=['num_policies'], how='left')\n",
        "test = test.merge(cltv_num_policies_5, on=['num_policies'], how='left')\n",
        "\n",
        "\n",
        "# Standardizing numerical feature\n",
        "scaler=StandardScaler()\n",
        "scaler.fit(test[['claim_amount']])\n",
        "test['claim_amount'] = scaler.transform(test[['claim_amount']])\n",
        "\n",
        "# One-hot encode the categorical feature\n",
        "test = pd.get_dummies(test, columns=[\"gender\",\"area\",\"qualification\",\"income\",\"num_policies\",\"policy\",\"type_of_policy\"])\n",
        "\n",
        "Predict_CLTV['cltv'] = best_model.predict(test)\n",
        "Predict_CLTV.to_csv(\"Predict_CLTV.csv\",index=False)"
      ],
      "metadata": {
        "id": "ADC2v1c3b1xi",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}